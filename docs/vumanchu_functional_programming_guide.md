# VuManChu Functional Programming Enhancement Guide

*Date: 2025-06-24*
*Agent 7: VuManChu Documentation Specialist - Batch 9 FP Transformation*

## ðŸ“‹ Overview

This document provides comprehensive guidance on the functional programming (FP) enhancements made to the VuManChu Cipher indicators. These enhancements improve reliability, performance, and maintainability while maintaining 100% backward compatibility with existing implementations.

## ðŸŽ¯ Key Functional Programming Principles Applied

### 1. **Immutability**
All VuManChu calculations now use immutable data structures, preventing state-related bugs that can occur in traditional imperative implementations.

```python
# BEFORE: Mutable state (potential bugs)
class VuManChuCalculator:
    def __init__(self):
        self.state = {"wt1": 0, "wt2": 0}  # Mutable state

    def update_state(self, new_wt1, new_wt2):
        self.state["wt1"] = new_wt1  # Mutation can cause issues
        self.state["wt2"] = new_wt2

# AFTER: Immutable approach (FP enhancement)
from dataclasses import dataclass
from typing import NamedTuple

@dataclass(frozen=True)  # Immutable by design
class VuManchuState:
    wt1: float
    wt2: float
    timestamp: datetime

    def with_updated_waves(self, new_wt1: float, new_wt2: float) -> 'VuManchuState':
        """Return new state instance instead of mutating current one."""
        return VuManchuState(
            wt1=new_wt1,
            wt2=new_wt2,
            timestamp=datetime.now()
        )
```

### 2. **Pure Functions**
All calculation functions are pure - they produce the same output for the same input with no side effects.

```python
# BEFORE: Impure function (can have side effects)
def calculate_wavetrend_impure(self, data):
    # Modifies internal state
    self.last_calculation_time = datetime.now()
    self.calculation_count += 1

    # Calculation logic mixed with side effects
    result = some_calculation(data)
    self.save_to_cache(result)  # Side effect
    return result

# AFTER: Pure function (FP enhancement)
def calculate_wavetrend_pure(
    src: np.ndarray,
    channel_length: int,
    average_length: int,
    ma_length: int
) -> tuple[np.ndarray, np.ndarray]:
    """
    Pure function: same input always produces same output.
    No side effects, no external state dependencies.
    """
    # Input validation
    if len(src) < max(channel_length, average_length, ma_length):
        return np.full_like(src, np.nan), np.full_like(src, np.nan)

    # Pure calculations
    esa = calculate_ema(src, channel_length)
    deviation = np.abs(src - esa)
    de = calculate_ema(deviation, channel_length)
    de = np.where(de == 0, 1e-6, de)  # Safe division

    ci = (src - esa) / (0.015 * de)
    ci = np.clip(ci, -100, 100)  # Bound extreme values

    tci = calculate_ema(ci, average_length)
    wt1 = tci
    wt2 = calculate_sma(wt1, ma_length)

    return wt1, wt2
```

### 3. **Composability**
Small, focused functions that combine elegantly to create complex behaviors.

```python
# Functional composition for VuManChu analysis
from functools import partial
from typing import Callable

# Small, focused functions
calculate_hlc3_fn = partial(calculate_hlc3)
detect_crossovers_fn = partial(detect_crossovers)
analyze_patterns_fn = partial(analyze_diamond_patterns)

# Compose them into complex analysis pipeline
def vumanchu_analysis_pipeline(
    ohlcv: np.ndarray,
    config: dict
) -> VuManchuSignalSet:
    """Composed analysis pipeline using functional approach."""

    # Extract price data
    high, low, close = ohlcv[:, 1], ohlcv[:, 2], ohlcv[:, 3]

    # Compose calculations
    hlc3 = calculate_hlc3_fn(high, low, close)
    wt1, wt2 = calculate_wavetrend_oscillator(hlc3, **config)
    bullish_cross, bearish_cross = detect_crossovers_fn(wt1, wt2)
    diamond_patterns = analyze_patterns_fn(wt1, wt2, **config)

    # Compose results
    return create_signal_set(wt1, wt2, diamond_patterns, **config)
```

### 4. **Error Handling Through Types**
Using Option and Either types for robust error handling.

```python
from bot.fp.core.option import Option, Some, Nothing
from bot.fp.core.either import Either, Left, Right

def safe_calculate_rsi(prices: list[float], period: int) -> Option[float]:
    """Calculate RSI with safe error handling using Option type."""
    if len(prices) < period or period <= 0:
        return Nothing()

    try:
        # Calculate gains and losses
        gains = []
        losses = []

        for i in range(1, len(prices)):
            change = prices[i] - prices[i-1]
            if change > 0:
                gains.append(change)
                losses.append(0)
            else:
                gains.append(0)
                losses.append(abs(change))

        if len(gains) < period:
            return Nothing()

        # Calculate average gains/losses
        avg_gain = sum(gains[-period:]) / period
        avg_loss = sum(losses[-period:]) / period

        if avg_loss == 0:
            return Some(100.0)  # RSI = 100 when no losses

        rs = avg_gain / avg_loss
        rsi = 100 - (100 / (1 + rs))

        return Some(rsi)

    except Exception:
        return Nothing()

# Usage with Option type
rsi_result = safe_calculate_rsi(prices, 14)
rsi_result.map(lambda rsi: f"RSI: {rsi:.2f}").or_else("RSI calculation failed")
```

## ðŸ”§ Enhanced VuManChu Components

### 1. **Functional WaveTrend Oscillator**

The core WaveTrend calculation has been enhanced with functional programming principles:

```python
def calculate_wavetrend_oscillator(
    src: np.ndarray,
    channel_length: int,
    average_length: int,
    ma_length: int
) -> tuple[np.ndarray, np.ndarray]:
    """
    Enhanced WaveTrend oscillator with functional programming improvements.

    Key FP Enhancements:
    1. Pure function - no side effects
    2. Immutable inputs and outputs
    3. Comprehensive input validation
    4. Safe mathematical operations
    5. Predictable error handling
    """
    # Validate inputs (fail-fast principle)
    if len(src) < max(channel_length, average_length, ma_length):
        return np.full_like(src, np.nan), np.full_like(src, np.nan)

    # Pure functional calculations
    esa = calculate_ema(src, channel_length)
    deviation = np.abs(src - esa)
    de = calculate_ema(deviation, channel_length)

    # FP Enhancement: Safe division with automatic zero protection
    de = np.where(de == 0, 1e-6, de)

    # FP Enhancement: Bounded calculations prevent extreme values
    ci = (src - esa) / (0.015 * de)
    ci = np.clip(ci, -100, 100)

    # Continue with pure calculations
    tci = calculate_ema(ci, average_length)
    wt1 = tci
    wt2 = calculate_sma(wt1, ma_length)

    return wt1, wt2
```

### 2. **Enhanced Pattern Detection**

Pattern detection has been redesigned using functional composition:

```python
def analyze_diamond_patterns_functional(
    wt1: np.ndarray,
    wt2: np.ndarray,
    overbought: float = 45.0,
    oversold: float = -45.0
) -> list[DiamondPattern]:
    """
    Functional approach to diamond pattern detection.

    FP Enhancements:
    1. Pure function with no external dependencies
    2. Immutable pattern objects
    3. Functional composition of detection logic
    4. Type-safe return values
    """
    # Early return for insufficient data (fail-fast)
    if len(wt1) < 2 or len(wt2) < 2:
        return []

    # Functional composition: detect crossovers
    bullish_cross, bearish_cross = detect_crossovers(wt1, wt2)

    # Functional composition: analyze patterns
    patterns = []
    for i in range(1, len(wt1)):
        # Red Diamond detection
        red_diamond = detect_red_diamond_pattern(
            i, wt1, wt2, bullish_cross, bearish_cross, overbought, oversold
        )
        if red_diamond:
            patterns.append(red_diamond)

        # Green Diamond detection
        green_diamond = detect_green_diamond_pattern(
            i, wt1, wt2, bullish_cross, bearish_cross, overbought, oversold
        )
        if green_diamond:
            patterns.append(green_diamond)

    return patterns

def detect_red_diamond_pattern(
    index: int,
    wt1: np.ndarray,
    wt2: np.ndarray,
    bullish_cross: np.ndarray,
    bearish_cross: np.ndarray,
    overbought: float,
    oversold: float
) -> DiamondPattern | None:
    """Pure function to detect red diamond pattern."""
    if not (bearish_cross[index] and wt2[index] > overbought):
        return None

    # Look for prior bullish cross in oversold
    lookback_start = max(0, index - 10)
    for j in range(lookback_start, index):
        if bullish_cross[j] and wt2[j] < oversold:
            strength = min(abs(wt1[index] - wt2[index]) / 10, 1.0)
            return DiamondPattern(
                timestamp=datetime.now(),
                pattern_type="red_diamond",
                wt1_cross_condition=True,
                wt2_cross_condition=True,
                strength=strength,
                overbought_level=overbought,
                oversold_level=oversold,
            )

    return None
```

### 3. **Immutable Signal Sets**

All signal results are now represented as immutable data structures:

```python
@dataclass(frozen=True)
class VuManchuSignalSet:
    """Immutable signal set for VuManChu analysis."""
    timestamp: datetime
    vumanchu_result: VuManchuResult
    diamond_patterns: tuple[DiamondPattern, ...]  # Immutable tuple
    yellow_cross_signals: tuple[YellowCrossSignal, ...]
    candle_patterns: tuple[CandlePattern, ...]
    divergence_patterns: tuple[DivergencePattern, ...]
    composite_signal: CompositeSignal | None

    def with_updated_patterns(
        self,
        new_patterns: list[DiamondPattern]
    ) -> 'VuManchuSignalSet':
        """Return new signal set with updated patterns (immutable)."""
        return VuManchuSignalSet(
            timestamp=self.timestamp,
            vumanchu_result=self.vumanchu_result,
            diamond_patterns=tuple(new_patterns),  # Create new tuple
            yellow_cross_signals=self.yellow_cross_signals,
            candle_patterns=self.candle_patterns,
            divergence_patterns=self.divergence_patterns,
            composite_signal=self.composite_signal,
        )

    def filter_high_confidence_signals(self, min_confidence: float) -> 'VuManchuSignalSet':
        """Return new signal set with only high-confidence signals."""
        filtered_diamonds = tuple(
            p for p in self.diamond_patterns
            if p.strength >= min_confidence
        )
        filtered_yellows = tuple(
            s for s in self.yellow_cross_signals
            if s.confidence >= min_confidence
        )

        return VuManchuSignalSet(
            timestamp=self.timestamp,
            vumanchu_result=self.vumanchu_result,
            diamond_patterns=filtered_diamonds,
            yellow_cross_signals=filtered_yellows,
            candle_patterns=self.candle_patterns,
            divergence_patterns=self.divergence_patterns,
            composite_signal=self.composite_signal,
        )
```

## ðŸ§ª Property-Based Testing

The functional enhancements include comprehensive property-based testing to ensure mathematical correctness:

### 1. **Mathematical Properties Testing**

```python
from hypothesis import given, strategies as st
import numpy as np

@given(st.lists(st.floats(min_value=0.01, max_value=10000), min_size=30, max_size=1000))
def test_wavetrend_mathematical_properties(prices):
    """Test mathematical properties of WaveTrend calculation."""
    prices_array = np.array(prices, dtype=np.float64)
    wt1, wt2 = calculate_wavetrend_oscillator(prices_array, 9, 18, 3)

    # Property: Results should be deterministic
    wt1_2, wt2_2 = calculate_wavetrend_oscillator(prices_array, 9, 18, 3)
    np.testing.assert_array_equal(wt1, wt1_2)
    np.testing.assert_array_equal(wt2, wt2_2)

    # Property: Valid numeric results (no infinite values)
    valid_wt1 = wt1[~np.isnan(wt1)]
    valid_wt2 = wt2[~np.isnan(wt2)]
    assert not np.any(np.isinf(valid_wt1))
    assert not np.any(np.isinf(valid_wt2))

    # Property: Results should be within reasonable bounds
    if len(valid_wt1) > 0:
        assert np.all(valid_wt1 >= -1000) and np.all(valid_wt1 <= 1000)
    if len(valid_wt2) > 0:
        assert np.all(valid_wt2 >= -1000) and np.all(valid_wt2 <= 1000)

@given(
    st.lists(st.floats(min_value=10, max_value=1000), min_size=50),
    st.integers(min_value=5, max_value=30),
    st.integers(min_value=10, max_value=50),
    st.integers(min_value=2, max_value=10)
)
def test_wavetrend_parameter_sensitivity(prices, channel_len, avg_len, ma_len):
    """Test WaveTrend sensitivity to parameter changes."""
    prices_array = np.array(prices, dtype=np.float64)

    # Calculate with original parameters
    wt1_orig, wt2_orig = calculate_wavetrend_oscillator(prices_array, channel_len, avg_len, ma_len)

    # Calculate with modified parameters
    wt1_mod, wt2_mod = calculate_wavetrend_oscillator(prices_array, channel_len + 1, avg_len + 1, ma_len)

    # Property: Small parameter changes should produce reasonable result differences
    if not np.any(np.isnan(wt1_orig)) and not np.any(np.isnan(wt1_mod)):
        # Results should be different but not drastically so
        diff = np.abs(wt1_orig - wt1_mod)
        valid_diff = diff[~np.isnan(diff)]
        if len(valid_diff) > 0:
            # Changes should be measurable but bounded
            assert np.mean(valid_diff) < 50  # Reasonable sensitivity
```

### 2. **Invariant Testing**

```python
@given(st.lists(st.floats(min_value=0.01, max_value=1000), min_size=100))
def test_diamond_pattern_invariants(prices):
    """Test invariants for diamond pattern detection."""
    prices_array = np.array(prices, dtype=np.float64)

    # Create OHLCV data from prices
    ohlcv = create_ohlcv_from_prices(prices_array)

    # Calculate patterns
    signal_set = vumanchu_comprehensive_analysis(ohlcv)

    # Invariant: Pattern timestamps should be consistent
    for pattern in signal_set.diamond_patterns:
        assert isinstance(pattern.timestamp, datetime)
        assert pattern.timestamp <= datetime.now()

    # Invariant: Pattern strength should be bounded
    for pattern in signal_set.diamond_patterns:
        assert 0.0 <= pattern.strength <= 1.0

    # Invariant: Pattern types should be valid
    valid_types = {"red_diamond", "green_diamond"}
    for pattern in signal_set.diamond_patterns:
        assert pattern.pattern_type in valid_types

    # Invariant: Overbought/oversold levels should be consistent
    for pattern in signal_set.diamond_patterns:
        assert pattern.overbought_level > pattern.oversold_level

def create_ohlcv_from_prices(prices: np.ndarray) -> np.ndarray:
    """Helper to create OHLCV data from price sequence."""
    n = len(prices)
    ohlcv = np.zeros((n, 5))

    for i in range(n):
        open_price = prices[i]
        close_price = prices[i] * (1 + np.random.normal(0, 0.01))
        high_price = max(open_price, close_price) * (1 + abs(np.random.normal(0, 0.005)))
        low_price = min(open_price, close_price) * (1 - abs(np.random.normal(0, 0.005)))
        volume = np.random.uniform(1000, 10000)

        ohlcv[i] = [open_price, high_price, low_price, close_price, volume]

    return ohlcv
```

## ðŸ”’ Backward Compatibility Implementation

The functional enhancements are designed to be completely backward compatible:

### 1. **Adapter Pattern**

```python
class VuManchuCompatibilityAdapter:
    """Adapter to bridge functional and imperative implementations."""

    def __init__(self, implementation_mode: str = "original"):
        self.implementation_mode = implementation_mode
        self._functional_calculator = None
        self._original_calculator = None

    def calculate_all(
        self,
        market_data: pd.DataFrame,
        dominance_candles: pd.DataFrame | None = None
    ) -> pd.DataFrame:
        """Backward compatible calculate_all method."""
        if dominance_candles is not None:
            logger.debug("dominance_candles ignored - VuManChu doesn't use dominance data")

        if self.implementation_mode == "functional":
            return self._calculate_functional(market_data)
        else:
            return self._calculate_original(market_data)

    def _calculate_functional(self, df: pd.DataFrame) -> pd.DataFrame:
        """Use functional implementation internally."""
        # Convert DataFrame to array for functional processing
        ohlcv = df[['open', 'high', 'low', 'close', 'volume']].values

        # Use functional calculation
        signal_set = vumanchu_comprehensive_analysis(ohlcv)

        # Convert back to DataFrame format expected by existing code
        return self._convert_signal_set_to_dataframe(signal_set, df.index)

    def _convert_signal_set_to_dataframe(
        self,
        signal_set: VuManchuSignalSet,
        index: pd.Index
    ) -> pd.DataFrame:
        """Convert functional results to expected DataFrame format."""
        result = pd.DataFrame(index=index)

        # Extract core VuManChu values
        result['wt1'] = signal_set.vumanchu_result.wave_a
        result['wt2'] = signal_set.vumanchu_result.wave_b
        result['cipher_a_signal'] = 1 if signal_set.vumanchu_result.signal == "LONG" else (
            -1 if signal_set.vumanchu_result.signal == "SHORT" else 0
        )

        # Calculate confidence from patterns
        pattern_count = len(signal_set.diamond_patterns) + len(signal_set.yellow_cross_signals)
        result['cipher_a_confidence'] = min(pattern_count * 0.2, 1.0)

        # Add pattern indicators
        result['cipher_a_diamond'] = len(signal_set.diamond_patterns) > 0
        result['cipher_a_yellow_cross'] = len(signal_set.yellow_cross_signals) > 0

        # Add composite signal information
        if signal_set.composite_signal:
            result['combined_signal'] = signal_set.composite_signal.signal_direction
            result['combined_confidence'] = signal_set.composite_signal.confidence
            result['signal_agreement'] = signal_set.composite_signal.agreement_score > 0.5

        return result
```

### 2. **Method Delegation**

```python
class VuManChuIndicators:
    """Enhanced VuManChu with functional programming support."""

    def __init__(self, implementation_mode: str = "original", **kwargs):
        self.implementation_mode = implementation_mode
        self.cipher_a = CipherA(use_functional_calculations=(implementation_mode == "functional"))
        self.cipher_b = CipherB(use_functional_calculations=(implementation_mode == "functional"))
        self.adapter = VuManchuCompatibilityAdapter(implementation_mode)

    def calculate_all(
        self,
        market_data: pd.DataFrame,
        dominance_candles: pd.DataFrame | None = None
    ) -> pd.DataFrame:
        """
        PRESERVED BACKWARD COMPATIBILITY METHOD.

        This method maintains the exact same signature and behavior as the original
        implementation, but can optionally use functional enhancements internally.
        """
        return self.adapter.calculate_all(market_data, dominance_candles)

    def calculate(
        self,
        df: pd.DataFrame,
        include_interpretation: bool = True
    ) -> pd.DataFrame:
        """Enhanced calculate method with optional functional mode."""
        if self.implementation_mode == "functional":
            return self._calculate_with_functional_enhancements(df, include_interpretation)
        else:
            return self._calculate_with_original_implementation(df, include_interpretation)

    def get_latest_state(self, df: pd.DataFrame) -> dict:
        """PRESERVED: Get latest state for LLM analysis."""
        result = self.calculate(df)
        if len(result) == 0:
            return self._get_fallback_state()

        latest = result.iloc[-1]
        return {
            "wt1": float(latest.get("wt1", 0.0)),
            "wt2": float(latest.get("wt2", 0.0)),
            "cipher_a_signal": int(latest.get("cipher_a_signal", 0)),
            "cipher_a_confidence": float(latest.get("cipher_a_confidence", 0.0)),
            "implementation_mode": self.implementation_mode,
            "calculation_timestamp": datetime.now().isoformat(),
        }
```

## ðŸš€ Performance Optimizations

### 1. **Vectorized Operations**

```python
def calculate_ema_vectorized(values: np.ndarray, period: int) -> np.ndarray:
    """Vectorized EMA calculation for better performance."""
    if len(values) < period:
        return np.full_like(values, np.nan)

    alpha = 2.0 / (period + 1)

    # Use numba for JIT compilation if available
    try:
        import numba
        return _calculate_ema_numba(values, alpha, period)
    except ImportError:
        return _calculate_ema_numpy(values, alpha, period)

def _calculate_ema_numpy(values: np.ndarray, alpha: float, period: int) -> np.ndarray:
    """NumPy-based EMA calculation."""
    ema = np.full_like(values, np.nan, dtype=np.float64)

    # Initialize with SMA
    ema[period - 1] = np.mean(values[:period])

    # Vectorized calculation for remaining values
    for i in range(period, len(values)):
        ema[i] = alpha * values[i] + (1 - alpha) * ema[i - 1]

    return ema

@numba.jit(nopython=True)
def _calculate_ema_numba(values: np.ndarray, alpha: float, period: int) -> np.ndarray:
    """Numba-accelerated EMA calculation."""
    ema = np.full_like(values, np.nan, dtype=np.float64)

    # Initialize with SMA
    sma_sum = 0.0
    for i in range(period):
        sma_sum += values[i]
    ema[period - 1] = sma_sum / period

    # Calculate EMA
    for i in range(period, len(values)):
        ema[i] = alpha * values[i] + (1 - alpha) * ema[i - 1]

    return ema
```

### 2. **Memory Optimization**

```python
def calculate_wavetrend_memory_optimized(
    src: np.ndarray,
    channel_length: int,
    average_length: int,
    ma_length: int
) -> tuple[np.ndarray, np.ndarray]:
    """Memory-optimized WaveTrend calculation."""
    # Pre-allocate output arrays
    wt1 = np.full_like(src, np.nan, dtype=np.float64)
    wt2 = np.full_like(src, np.nan, dtype=np.float64)

    # Early return for insufficient data
    min_length = max(channel_length, average_length, ma_length)
    if len(src) < min_length:
        return wt1, wt2

    # Reuse arrays to minimize allocations
    temp_array = np.empty_like(src, dtype=np.float64)

    # Calculate ESA in-place
    esa = calculate_ema_inplace(src, channel_length, temp_array)

    # Calculate deviation in-place
    np.abs(src - esa, out=temp_array)
    de = calculate_ema_inplace(temp_array, channel_length, temp_array)

    # Safe division with in-place operations
    np.maximum(de, 1e-6, out=de)

    # Calculate CI
    np.subtract(src, esa, out=temp_array)
    np.divide(temp_array, (0.015 * de), out=temp_array)
    np.clip(temp_array, -100, 100, out=temp_array)

    # Calculate TCI (wt1)
    wt1 = calculate_ema_inplace(temp_array, average_length, wt1)

    # Calculate wt2
    wt2 = calculate_sma_inplace(wt1, ma_length, wt2)

    return wt1, wt2

def calculate_ema_inplace(
    values: np.ndarray,
    period: int,
    out: np.ndarray
) -> np.ndarray:
    """In-place EMA calculation to minimize memory allocation."""
    if len(values) < period:
        out.fill(np.nan)
        return out

    alpha = 2.0 / (period + 1)

    # Initialize output array
    out.fill(np.nan)

    # SMA for initial value
    out[period - 1] = np.mean(values[:period])

    # EMA calculation
    for i in range(period, len(values)):
        out[i] = alpha * values[i] + (1 - alpha) * out[i - 1]

    return out
```

## ðŸ” Debugging and Monitoring

### 1. **Functional Debugging Tools**

```python
from functools import wraps
from typing import Any, Callable, TypeVar

T = TypeVar('T')

def debug_pure_function(func: Callable[..., T]) -> Callable[..., T]:
    """Decorator to debug pure functions without side effects."""
    @wraps(func)
    def wrapper(*args, **kwargs):
        # Log inputs (safe because functions are pure)
        logger.debug(f"Calling {func.__name__} with args: {args[:2]}..., kwargs: {kwargs}")

        # Time the execution
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()

        # Log execution time and basic result info
        logger.debug(f"{func.__name__} completed in {(end_time - start_time) * 1000:.2f}ms")

        if isinstance(result, tuple) and len(result) == 2:
            # Likely wt1, wt2 tuple
            wt1, wt2 = result
            if isinstance(wt1, np.ndarray) and isinstance(wt2, np.ndarray):
                logger.debug(f"Result shapes: wt1={wt1.shape}, wt2={wt2.shape}")
                logger.debug(f"Non-NaN values: wt1={np.sum(~np.isnan(wt1))}, wt2={np.sum(~np.isnan(wt2))}")

        return result

    return wrapper

# Usage
@debug_pure_function
def calculate_wavetrend_debug(src, channel_length, average_length, ma_length):
    """Debug-enabled WaveTrend calculation."""
    return calculate_wavetrend_oscillator(src, channel_length, average_length, ma_length)
```

### 2. **Performance Monitoring**

```python
class VuManchuPerformanceMonitor:
    """Monitor performance of VuManChu calculations."""

    def __init__(self):
        self.calculation_times = []
        self.memory_usage = []
        self.error_counts = {}

    def monitor_calculation(self, func: Callable) -> Callable:
        """Monitor a calculation function."""
        @wraps(func)
        def wrapper(*args, **kwargs):
            # Memory before
            import psutil
            process = psutil.Process()
            memory_before = process.memory_info().rss

            # Time execution
            start_time = time.perf_counter()
            try:
                result = func(*args, **kwargs)
                self._record_success(start_time, memory_before)
                return result
            except Exception as e:
                self._record_error(e, start_time, memory_before)
                raise

        return wrapper

    def _record_success(self, start_time: float, memory_before: int):
        """Record successful calculation metrics."""
        end_time = time.perf_counter()
        calculation_time = (end_time - start_time) * 1000

        import psutil
        process = psutil.Process()
        memory_after = process.memory_info().rss
        memory_used = memory_after - memory_before

        self.calculation_times.append(calculation_time)
        self.memory_usage.append(memory_used)

    def _record_error(self, error: Exception, start_time: float, memory_before: int):
        """Record calculation error."""
        error_type = type(error).__name__
        self.error_counts[error_type] = self.error_counts.get(error_type, 0) + 1

    def get_performance_report(self) -> dict:
        """Get performance statistics."""
        if not self.calculation_times:
            return {"status": "No calculations recorded"}

        return {
            "calculation_count": len(self.calculation_times),
            "avg_calculation_time_ms": np.mean(self.calculation_times),
            "max_calculation_time_ms": np.max(self.calculation_times),
            "avg_memory_usage_mb": np.mean(self.memory_usage) / (1024 * 1024),
            "max_memory_usage_mb": np.max(self.memory_usage) / (1024 * 1024),
            "error_counts": dict(self.error_counts),
            "success_rate": (len(self.calculation_times) /
                           (len(self.calculation_times) + sum(self.error_counts.values())))
        }

# Global monitor instance
performance_monitor = VuManchuPerformanceMonitor()

# Apply monitoring to key functions
calculate_wavetrend_monitored = performance_monitor.monitor_calculation(
    calculate_wavetrend_oscillator
)
vumanchu_analysis_monitored = performance_monitor.monitor_calculation(
    vumanchu_comprehensive_analysis
)
```

## ðŸ“Š Migration Examples

### Example 1: Simple Migration

```python
# BEFORE: Original imperative approach
from bot.indicators.vumanchu import VuManChuIndicators

vumanchu = VuManChuIndicators()
result = vumanchu.calculate_all(market_data)

# AFTER: With functional enhancements (zero code changes required!)
vumanchu = VuManChuIndicators(implementation_mode="functional")
result = vumanchu.calculate_all(market_data)  # Same method, enhanced internally
```

### Example 2: Advanced Functional Usage

```python
# BEFORE: Working with raw calculation results
vumanchu = VuManChuIndicators()
result = vumanchu.calculate_all(df)
wt1_values = result['wt1'].dropna()
wt2_values = result['wt2'].dropna()

# Manual pattern detection
diamonds = []
for i in range(1, len(wt1_values)):
    if wt1_values.iloc[i] > wt2_values.iloc[i] and wt1_values.iloc[i-1] <= wt2_values.iloc[i-1]:
        # Manual crossover detection
        diamonds.append(("bullish_cross", i))

# AFTER: Using functional composition
from bot.fp.indicators.vumanchu_functional import vumanchu_comprehensive_analysis

ohlcv = df[['open', 'high', 'low', 'close', 'volume']].values
signal_set = vumanchu_comprehensive_analysis(ohlcv)

# Automatic pattern detection with rich metadata
high_confidence_diamonds = signal_set.filter_high_confidence_signals(0.8)
red_diamonds = [p for p in high_confidence_diamonds.diamond_patterns
                if p.pattern_type == "red_diamond"]

# Type-safe access to pattern properties
for diamond in red_diamonds:
    print(f"Red Diamond at {diamond.timestamp}: strength={diamond.strength:.2f}")
```

### Example 3: Real-time Processing

```python
# BEFORE: Imperative real-time processing
class VuManchuRealTimeProcessor:
    def __init__(self):
        self.vumanchu = VuManChuIndicators()
        self.historical_data = []
        self.last_signals = {}

    def process_candle(self, new_candle):
        self.historical_data.append(new_candle)  # Mutable state
        df = pd.DataFrame(self.historical_data)
        result = self.vumanchu.calculate_all(df)

        # Manual signal extraction
        if len(result) > 0:
            latest = result.iloc[-1]
            self.last_signals['wt1'] = latest['wt1']  # More mutable state
            self.last_signals['wt2'] = latest['wt2']

        return self.last_signals

# AFTER: Functional real-time processing
from bot.fp.indicators.vumanchu_functional import vumanchu_cipher

def process_candle_functional(new_candle: dict, historical_data: np.ndarray) -> VuManchuResult:
    """Pure functional candle processing."""
    # Create new data array (immutable approach)
    new_row = np.array([[
        new_candle['open'], new_candle['high'],
        new_candle['low'], new_candle['close'], new_candle['volume']
    ]])
    updated_data = np.vstack([historical_data, new_row])

    # Pure functional calculation
    return vumanchu_cipher(updated_data)

# Usage with immutable data flow
historical_ohlcv = np.array([])  # Start with empty array
for candle in real_time_candles:
    # Each call returns new state without modifying original
    result = process_candle_functional(candle, historical_ohlcv)

    # Update historical data for next iteration (immutable update)
    historical_ohlcv = np.vstack([historical_ohlcv, [[
        candle['open'], candle['high'], candle['low'],
        candle['close'], candle['volume']
    ]]])

    # Process signal (pure function call)
    if result.signal != "NEUTRAL":
        handle_trading_signal(result)  # Another pure function
```

## âœ… Summary

The VuManChu functional programming enhancements provide:

### **ðŸŽ¯ Core Benefits**
- **Reliability**: Immutable data structures prevent state-related bugs
- **Predictability**: Pure functions always produce the same output for the same input
- **Testability**: Property-based testing ensures mathematical correctness
- **Performance**: Vectorized operations and memory optimization
- **Maintainability**: Composable functions that are easy to understand and modify

### **ðŸ”’ Backward Compatibility**
- **Zero Breaking Changes**: All existing code continues to work unchanged
- **Optional Adoption**: Choose when and how to adopt functional patterns
- **Gradual Migration**: Mix imperative and functional approaches as needed
- **Same APIs**: Preserved method signatures and return types

### **ðŸš€ Enhanced Capabilities**
- **Better Error Handling**: Graceful degradation with meaningful fallbacks
- **Rich Type System**: Comprehensive validation and type safety
- **Advanced Patterns**: Diamond patterns, yellow crosses, divergences
- **Performance Monitoring**: Built-in metrics and profiling tools

The functional programming enhancements make VuManChu calculations more reliable and performant while maintaining the complete feature set that traders depend on.
